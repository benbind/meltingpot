diff --git a/.vscode/launch.json b/.vscode/launch.json
index e526052..23e4437 100644
--- a/.vscode/launch.json
+++ b/.vscode/launch.json
@@ -25,6 +25,21 @@
       "program": "${file}",
       "console": "integratedTerminal",
       "justMyCode": true
+    },
+    {
+      "name": "Docker: Python - General",
+      "type": "docker",
+      "request": "launch",
+      "preLaunchTask": "docker-run: debug",
+      "python": {
+        "pathMappings": [
+          {
+            "localRoot": "${workspaceFolder}",
+            "remoteRoot": "/app"
+          }
+        ],
+        "projectType": "general"
+      }
     }
   ]
 }
diff --git a/examples/pettingzoo/utils.py b/examples/pettingzoo/utils.py
index 35935f3..30aa027 100644
--- a/examples/pettingzoo/utils.py
+++ b/examples/pettingzoo/utils.py
@@ -18,7 +18,6 @@ import functools
 from gymnasium import utils as gym_utils
 import matplotlib.pyplot as plt
 from meltingpot import substrate
-from meltingpot.substrate import get_factory_from_config
 from ml_collections import config_dict
 from pettingzoo import utils as pettingzoo_utils
 from pettingzoo.utils import wrappers
diff --git a/examples/rllib/__init__.py b/examples/rllib/__init__.py
deleted file mode 100644
index 4ad7182..0000000
--- a/examples/rllib/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# Copyright 2023 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/rllib/self_play_train.py b/examples/rllib/self_play_train.py
deleted file mode 100644
index 496ea79..0000000
--- a/examples/rllib/self_play_train.py
+++ /dev/null
@@ -1,165 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Runs an example of a self-play training experiment."""
-
-import os
-
-from meltingpot import substrate
-import ray
-from ray import air
-from ray import tune
-from ray.rllib.algorithms import ppo
-from ray.rllib.policy import policy
-
-from . import utils
-
-
-def get_config(
-    substrate_name: str = "bach_or_stravinsky_in_the_matrix__repeated",
-    num_rollout_workers: int = 2,
-    rollout_fragment_length: int = 100,
-    train_batch_size: int = 6400,
-    fcnet_hiddens=(64, 64),
-    post_fcnet_hiddens=(256,),
-    lstm_cell_size: int = 256,
-    sgd_minibatch_size: int = 128,
-):
-  """Get the configuration for running an agent on a substrate using RLLib.
-
-  We need the following 2 pieces to run the training:
-
-  Args:
-    substrate_name: The name of the MeltingPot substrate, coming from
-      `substrate.AVAILABLE_SUBSTRATES`.
-    num_rollout_workers: The number of workers for playing games.
-    rollout_fragment_length: Unroll time for learning.
-    train_batch_size: Batch size (batch * rollout_fragment_length)
-    fcnet_hiddens: Fully connected layers.
-    post_fcnet_hiddens: Layer sizes after the fully connected torso.
-    lstm_cell_size: Size of the LSTM.
-    sgd_minibatch_size: Size of the mini-batch for learning.
-
-  Returns:
-    The configuration for running the experiment.
-  """
-  # Gets the default training configuration
-  config = ppo.PPOConfig()
-  # Number of arenas.
-  config.num_rollout_workers = num_rollout_workers
-  # This is to match our unroll lengths.
-  config.rollout_fragment_length = rollout_fragment_length
-  # Total (time x batch) timesteps on the learning update.
-  config.train_batch_size = train_batch_size
-  # Mini-batch size.
-  config.sgd_minibatch_size = sgd_minibatch_size
-  # Use the raw observations/actions as defined by the environment.
-  config.preprocessor_pref = None
-  # Use TensorFlow as the tensor framework.
-  config = config.framework("tf")
-  # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.
-  config.num_gpus = int(os.environ.get("RLLIB_NUM_GPUS", "0"))
-  config.log_level = "DEBUG"
-
-  # 2. Set environment config. This will be passed to
-  # the env_creator function via the register env lambda below.
-  player_roles = substrate.get_config(substrate_name).default_player_roles
-  config.env_config = {"substrate": substrate_name, "roles": player_roles}
-
-  config.env = "meltingpot"
-
-  # 4. Extract space dimensions
-  test_env = utils.env_creator(config.env_config)
-
-  # Setup PPO with policies, one per entry in default player roles.
-  policies = {}
-  player_to_agent = {}
-  for i in range(len(player_roles)):
-    rgb_shape = test_env.observation_space[f"player_{i}"]["RGB"].shape
-    sprite_x = rgb_shape[0] // 8
-    sprite_y = rgb_shape[1] // 8
-
-    policies[f"agent_{i}"] = policy.PolicySpec(
-        policy_class=None,  # use default policy
-        observation_space=test_env.observation_space[f"player_{i}"],
-        action_space=test_env.action_space[f"player_{i}"],
-        config={
-            "model": {
-                "conv_filters": [[16, [8, 8], 8],
-                                 [128, [sprite_x, sprite_y], 1]],
-            },
-        })
-    player_to_agent[f"player_{i}"] = f"agent_{i}"
-
-  def policy_mapping_fn(agent_id, **kwargs):
-    del kwargs
-    return player_to_agent[agent_id]
-
-  # 5. Configuration for multi-agent setup with one policy per role:
-  config.multi_agent(policies=policies, policy_mapping_fn=policy_mapping_fn)
-
-  # 6. Set the agent architecture.
-  # Definition of the model architecture.
-  # The strides of the first convolutional layer were chosen to perfectly line
-  # up with the sprites, which are 8x8.
-  # The final layer must be chosen specifically so that its output is
-  # [B, 1, 1, X]. See the explanation in
-  # https://docs.ray.io/en/latest/rllib-models.html#built-in-models. It is
-  # because rllib is unable to flatten to a vector otherwise.
-  # The acb models used as baselines in the meltingpot paper were not run using
-  # rllib, so they used a different configuration for the second convolutional
-  # layer. It was 32 channels, [4, 4] kernel shape, and stride = 1.
-  config.model["fcnet_hiddens"] = fcnet_hiddens
-  config.model["fcnet_activation"] = "relu"
-  config.model["conv_activation"] = "relu"
-  config.model["post_fcnet_hiddens"] = post_fcnet_hiddens
-  config.model["post_fcnet_activation"] = "relu"
-  config.model["use_lstm"] = True
-  config.model["lstm_use_prev_action"] = True
-  config.model["lstm_use_prev_reward"] = False
-  config.model["lstm_cell_size"] = lstm_cell_size
-
-  return config
-
-
-def train(config, num_iterations=1):
-  """Trains a model.
-
-  Args:
-    config: model config
-    num_iterations: number of iterations ot train for.
-
-  Returns:
-    Training results.
-  """
-  tune.register_env("meltingpot", utils.env_creator)
-  ray.init()
-  stop = {
-      "training_iteration": num_iterations,
-  }
-  return tune.Tuner(
-      "PPO",
-      param_space=config.to_dict(),
-      run_config=air.RunConfig(stop=stop, verbose=1),
-  ).fit()
-
-
-def main():
-  config = get_config()
-  results = train(config, num_iterations=1)
-  print(results)
-  assert results.num_errors == 0
-
-
-if __name__ == "__main__":
-  main()
diff --git a/examples/rllib/self_play_train_test.py b/examples/rllib/self_play_train_test.py
deleted file mode 100644
index 91de4a3..0000000
--- a/examples/rllib/self_play_train_test.py
+++ /dev/null
@@ -1,34 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Tests for the self_play_train.py."""
-
-from absl.testing import absltest
-
-from . import self_play_train
-
-
-class TrainingTests(absltest.TestCase):
-  """Tests for MeltingPotEnv for RLLib."""
-
-  def test_training(self):
-    config = self_play_train.get_config(
-        num_rollout_workers=1,
-        rollout_fragment_length=10,
-        train_batch_size=20,
-        sgd_minibatch_size=20,
-        fcnet_hiddens=(4,),
-        post_fcnet_hiddens=(4,),
-        lstm_cell_size=2)
-    results = self_play_train.train(config, num_iterations=1)
-    self.assertEqual(results.num_errors, 0)
diff --git a/examples/rllib/utils.py b/examples/rllib/utils.py
deleted file mode 100644
index 8aeadc4..0000000
--- a/examples/rllib/utils.py
+++ /dev/null
@@ -1,178 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""MeltingPotEnv as a MultiAgentEnv wrapper to interface with RLLib."""
-
-from typing import Tuple
-
-import dm_env
-import dmlab2d
-from gymnasium import spaces
-from meltingpot import substrate
-from meltingpot.utils.policies import policy
-from ml_collections import config_dict
-import numpy as np
-from ray.rllib import algorithms
-from ray.rllib.env import multi_agent_env
-from ray.rllib.policy import sample_batch
-
-from ..gym import utils
-
-PLAYER_STR_FORMAT = 'player_{index}'
-
-
-class MeltingPotEnv(multi_agent_env.MultiAgentEnv):
-  """An adapter between the Melting Pot substrates and RLLib MultiAgentEnv."""
-
-  def __init__(self, env: dmlab2d.Environment):
-    """Initializes the instance.
-
-    Args:
-      env: dmlab2d environment to wrap. Will be closed when this wrapper closes.
-    """
-    self._env = env
-    self._num_players = len(self._env.observation_spec())
-    self._ordered_agent_ids = [
-        PLAYER_STR_FORMAT.format(index=index)
-        for index in range(self._num_players)
-    ]
-    # RLLib requires environments to have the following member variables:
-    # observation_space, action_space, and _agent_ids
-    self._agent_ids = set(self._ordered_agent_ids)
-    # RLLib expects a dictionary of agent_id to observation or action,
-    # Melting Pot uses a tuple, so we convert
-    self.observation_space = self._convert_spaces_tuple_to_dict(
-        utils.spec_to_space(self._env.observation_spec()),
-        remove_world_observations=True)
-    self.action_space = self._convert_spaces_tuple_to_dict(
-        utils.spec_to_space(self._env.action_spec()))
-    super().__init__()
-
-  def reset(self, *args, **kwargs):
-    """See base class."""
-    timestep = self._env.reset()
-    return utils.timestep_to_observations(timestep), {}
-
-  def step(self, action_dict):
-    """See base class."""
-    actions = [action_dict[agent_id] for agent_id in self._ordered_agent_ids]
-    timestep = self._env.step(actions)
-    rewards = {
-        agent_id: timestep.reward[index]
-        for index, agent_id in enumerate(self._ordered_agent_ids)
-    }
-    done = {'__all__': timestep.last()}
-    info = {}
-
-    observations = utils.timestep_to_observations(timestep)
-    return observations, rewards, done, done, info
-
-  def close(self):
-    """See base class."""
-    self._env.close()
-
-  def get_dmlab2d_env(self):
-    """Returns the underlying DM Lab2D environment."""
-    return self._env
-
-  # Metadata is required by the gym `Env` class that we are extending, to show
-  # which modes the `render` method supports.
-  metadata = {'render.modes': ['rgb_array']}
-
-  def render(self) -> np.ndarray:
-    """Render the environment.
-
-    This allows you to set `record_env` in your training config, to record
-    videos of gameplay.
-
-    Returns:
-        np.ndarray: This returns a numpy.ndarray with shape (x, y, 3),
-        representing RGB values for an x-by-y pixel image, suitable for turning
-        into a video.
-    """
-    observation = self._env.observation()
-    world_rgb = observation[0]['WORLD.RGB']
-
-    # RGB mode is used for recording videos
-    return world_rgb
-
-  def _convert_spaces_tuple_to_dict(
-      self,
-      input_tuple: spaces.Tuple,
-      remove_world_observations: bool = False) -> spaces.Dict:
-    """Returns spaces tuple converted to a dictionary.
-
-    Args:
-      input_tuple: tuple to convert.
-      remove_world_observations: If True will remove non-player observations.
-    """
-    return spaces.Dict({
-        agent_id: (utils.remove_world_observations_from_space(input_tuple[i])
-                   if remove_world_observations else input_tuple[i])
-        for i, agent_id in enumerate(self._ordered_agent_ids)
-    })
-
-
-def env_creator(env_config):
-  """Outputs an environment for registering."""
-  env_config = config_dict.ConfigDict(env_config)
-  env = substrate.build(env_config['substrate'], roles=env_config['roles'])
-  env = MeltingPotEnv(env)
-  return env
-
-
-class RayModelPolicy(policy.Policy[policy.State]):
-  """Policy wrapping an RLLib model for inference.
-
-  Note: Currently only supports a single input, batching is not enabled
-  """
-
-  def __init__(self,
-               model: algorithms.Algorithm,
-               policy_id: str = sample_batch.DEFAULT_POLICY_ID) -> None:
-    """Initialize a policy instance.
-
-    Args:
-      model: An rllib.trainer.Trainer checkpoint.
-      policy_id: Which policy to use (if trained in multi_agent mode)
-    """
-    self._model = model
-    self._prev_action = 0
-    self._policy_id = policy_id
-
-  def step(self, timestep: dm_env.TimeStep,
-           prev_state: policy.State) -> Tuple[int, policy.State]:
-    """See base class."""
-    observations = {
-        key: value
-        for key, value in timestep.observation.items()
-        if 'WORLD' not in key
-    }
-
-    action, state, _ = self._model.compute_single_action(
-        observations,
-        prev_state,
-        policy_id=self._policy_id,
-        prev_action=self._prev_action,
-        prev_reward=timestep.reward)
-
-    self._prev_action = action
-    return action, state
-
-  def initial_state(self) -> policy.State:
-    """See base class."""
-    self._prev_action = 0
-    return self._model.get_policy(self._policy_id).get_initial_state()
-
-  def close(self) -> None:
-    """See base class."""
diff --git a/examples/rllib/utils_test.py b/examples/rllib/utils_test.py
deleted file mode 100644
index 2053b6e..0000000
--- a/examples/rllib/utils_test.py
+++ /dev/null
@@ -1,76 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Tests for utils.py."""
-
-from absl.testing import absltest
-from gymnasium.spaces import discrete
-from meltingpot import substrate
-from meltingpot.configs.substrates import commons_harvest__open
-
-from . import utils
-
-
-class MeltingPotEnvTests(absltest.TestCase):
-  """Tests for MeltingPotEnv for RLLib."""
-
-  def setUp(self):
-    super().setUp()
-    # Create a new MeltingPotEnv for each test case
-    env_config = substrate.get_config('commons_harvest__open')
-    roles = env_config.default_player_roles
-    self._num_players = len(roles)
-    self._env = utils.env_creator({
-        'substrate': 'commons_harvest__open',
-        'roles': roles,
-    })
-
-  def test_action_space_size(self):
-    """Test the action space is the correct size."""
-    actions_count = len(commons_harvest__open.ACTION_SET)
-    env_action_space = self._env.action_space['player_1']
-    self.assertEqual(env_action_space, discrete.Discrete(actions_count))
-
-  def test_reset_number_agents(self):
-    """Test that reset() returns observations for all agents."""
-    obs, _ = self._env.reset()
-    self.assertLen(obs, self._num_players)
-
-  def test_step(self):
-    """Test step() returns rewards for all agents."""
-    self._env.reset()
-
-    # Create dummy actions
-    actions = {}
-    for player_idx in range(0, self._num_players):
-      actions['player_' + str(player_idx)] = 1
-
-    # Step
-    _, rewards, _, _, _ = self._env.step(actions)
-
-    # Check we have one reward per agent
-    self.assertLen(rewards, self._num_players)
-
-  def test_render_modes_metadata(self):
-    """Test that render modes are given in the metadata."""
-    self.assertIn('rgb_array', self._env.metadata['render.modes'])
-
-  def test_render_rgb_array(self):
-    """Test that render('rgb_array') returns the full world."""
-    self._env.reset()
-    render = self._env.render()
-    self.assertEqual(render.shape, (144, 192, 3))
-
-
-if __name__ == '__main__':
-  absltest.main()
diff --git a/examples/rllib/view_models.py b/examples/rllib/view_models.py
deleted file mode 100644
index c9b23c1..0000000
--- a/examples/rllib/view_models.py
+++ /dev/null
@@ -1,109 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Runs the bots trained in self_play_train.py and renders in pygame.
-
-You must provide experiment_state, expected to be
-~/ray_results/PPO/experiment_state_YOUR_RUN_ID.json
-"""
-
-import argparse
-
-import dm_env
-from dmlab2d.ui_renderer import pygame
-import numpy as np
-from ray.rllib.algorithms.registry import get_trainer_class
-from ray.tune.analysis.experiment_analysis import ExperimentAnalysis
-from ray.tune.registry import register_env
-
-from . import utils
-
-
-def main():
-  parser = argparse.ArgumentParser(description=__doc__)
-  parser.add_argument(
-      "--experiment_state",
-      type=str,
-      default="~/ray_results/PPO",
-      help="ray.tune experiment_state to load. The default setting will load"
-      " the last training run created by self_play_train.py. If you want to use"
-      " a specific run, provide a path, expected to be of the format "
-      " ~/ray_results/PPO/experiment_state-DATETIME.json")
-
-  args = parser.parse_args()
-
-  agent_algorithm = "PPO"
-
-  register_env("meltingpot", utils.env_creator)
-
-  experiment = ExperimentAnalysis(
-      args.experiment_state,
-      default_metric="episode_reward_mean",
-      default_mode="max")
-
-  config = experiment.best_config
-  checkpoint_path = experiment.best_checkpoint
-
-  trainer = get_trainer_class(agent_algorithm)(config=config)
-  trainer.restore(checkpoint_path)
-
-  # Create a new environment to visualise
-  env = utils.env_creator(config["env_config"]).get_dmlab2d_env()
-
-  bots = [
-      utils.RayModelPolicy(trainer, f"agent_{i}")
-      for i in range(len(config["env_config"]["default_player_roles"]))
-  ]
-
-  timestep = env.reset()
-  states = [bot.initial_state() for bot in bots]
-  actions = [0] * len(bots)
-
-  # Configure the pygame display
-  scale = 4
-  fps = 5
-
-  pygame.init()
-  clock = pygame.time.Clock()
-  pygame.display.set_caption("DM Lab2d")
-  obs_spec = env.observation_spec()
-  shape = obs_spec[0]["WORLD.RGB"].shape
-  game_display = pygame.display.set_mode(
-      (int(shape[1] * scale), int(shape[0] * scale)))
-
-  for _ in range(config["horizon"]):
-    obs = timestep.observation[0]["WORLD.RGB"]
-    obs = np.transpose(obs, (1, 0, 2))
-    surface = pygame.surfarray.make_surface(obs)
-    rect = surface.get_rect()
-    surf = pygame.transform.scale(surface,
-                                  (int(rect[2] * scale), int(rect[3] * scale)))
-
-    game_display.blit(surf, dest=(0, 0))
-    pygame.display.update()
-    clock.tick(fps)
-
-    for i, bot in enumerate(bots):
-      timestep_bot = dm_env.TimeStep(
-          step_type=timestep.step_type,
-          reward=timestep.reward[i],
-          discount=timestep.discount,
-          observation=timestep.observation[i])
-
-      actions[i], states[i] = bot.step(timestep_bot, states[i])
-
-    timestep = env.step(actions)
-
-
-if __name__ == "__main__":
-  main()
diff --git a/examples/tutorial/__init__.py b/examples/tutorial/__init__.py
deleted file mode 100644
index e073588..0000000
--- a/examples/tutorial/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/tutorial/harvest/__init__.py b/examples/tutorial/harvest/__init__.py
deleted file mode 100644
index e073588..0000000
--- a/examples/tutorial/harvest/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/tutorial/harvest/configs/__init__.py b/examples/tutorial/harvest/configs/__init__.py
deleted file mode 100644
index e073588..0000000
--- a/examples/tutorial/harvest/configs/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/tutorial/harvest/configs/environment/__init__.py b/examples/tutorial/harvest/configs/environment/__init__.py
deleted file mode 100644
index e073588..0000000
--- a/examples/tutorial/harvest/configs/environment/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/tutorial/harvest/configs/environment/harvest.py b/examples/tutorial/harvest/configs/environment/harvest.py
deleted file mode 100644
index 789ef92..0000000
--- a/examples/tutorial/harvest/configs/environment/harvest.py
+++ /dev/null
@@ -1,46 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Configuration for tutorial level: Harvest."""
-
-from ml_collections import config_dict
-
-
-def get_config():
-  """Default configuration for the Harvest level."""
-  config = config_dict.ConfigDict()
-
-  # Basic configuration.
-  config.individual_observation_names = []
-  config.global_observation_names = ["WORLD.RGB"]
-
-  # Lua script configuration.
-  config.lab2d_settings = {
-      "levelName":
-          "harvest",
-      "levelDirectory":
-          "examples/tutorial/harvest/levels",
-      "maxEpisodeLengthFrames":
-          100,
-      "numPlayers":
-          0,
-      "spriteSize":
-          8,
-      "simulation": {
-          "map": " ",
-          "prefabs": {},
-          "charPrefabMap": {},
-      },
-  }
-
-  return config
diff --git a/examples/tutorial/harvest/configs/environment/harvest_finished.py b/examples/tutorial/harvest/configs/environment/harvest_finished.py
deleted file mode 100644
index 7b40d65..0000000
--- a/examples/tutorial/harvest/configs/environment/harvest_finished.py
+++ /dev/null
@@ -1,227 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""Configuration for finished tutorial level: Harvest."""
-
-from meltingpot.utils.substrates import shapes
-from ml_collections import config_dict
-
-SPAWN_POINT = {
-    "name": "spawn_point",
-    "components": [
-        {
-            "component": "StateManager",
-            "kwargs": {
-                "initialState": "spawnPoint",
-                "stateConfigs": [{
-                    "state": "spawnPoint",
-                    "groups": ["spawnPoints"],
-                }],
-            }
-        },
-        {
-            "component": "Transform",
-        },
-    ]
-}
-
-AVATAR = {
-    "name": "avatar",
-    "components": [
-        {
-            "component": "StateManager",
-            "kwargs": {
-                "initialState": "player",
-                "stateConfigs": [
-                    {"state": "player",
-                     "layer": "upperPhysical",
-                     "contact": "avatar",
-                     "sprite": "Avatar",},
-                ]
-            }
-        },
-        {
-            "component": "Transform",
-        },
-        {
-            "component": "Appearance",
-            "kwargs": {
-                "renderMode": "ascii_shape",
-                "spriteNames": ["Avatar"],
-                "spriteShapes": [shapes.CUTE_AVATAR],
-                "palettes": [{}],  # Will be overridden
-                "noRotates": [True],
-            }
-        },
-        {
-            "component": "Avatar",
-            "kwargs": {
-                "aliveState": "player",
-                "waitState": "playerWait",
-                "spawnGroup": "spawnPoints",
-                "view": {
-                    "left": 3,
-                    "right": 3,
-                    "forward": 5,
-                    "backward": 1,
-                    "centered": False,
-                }
-            }
-        },
-    ]
-}
-
-
-WALL = {
-    "name": "wall",
-    "components": [
-        {
-            "component": "StateManager",
-            "kwargs": {
-                "initialState": "wall",
-                "stateConfigs": [{
-                    "state": "wall",
-                    "layer": "upperPhysical",
-                    "sprite": "Wall",
-                }],
-            }
-        },
-        {
-            "component": "Transform",
-        },
-        {
-            "component": "Appearance",
-            "kwargs": {
-                "renderMode": "ascii_shape",
-                "spriteNames": ["Wall",],
-                "spriteShapes": [shapes.WALL],
-                "palettes": [shapes.WALL_PALETTE],
-                "noRotates": [True],
-            }
-        },
-        {
-            "component": "BeamBlocker",
-            "kwargs": {
-                "beamType": "gift"
-            }
-        },
-        {
-            "component": "BeamBlocker",
-            "kwargs": {
-                "beamType": "zap"
-            }
-        },
-    ]
-}
-
-APPLE = {
-    "name": "apple",
-    "components": [
-        {
-            "component": "StateManager",
-            "kwargs": {
-                "initialState": "apple",
-                "stateConfigs": [{
-                    "state": "apple",
-                    "layer": "lowerPhysical",
-                    "sprite": "Apple",
-                }, {
-                    "state": "appleWait",
-                }],
-            }
-        },
-        {
-            "component": "Transform",
-        },
-        {
-            "component": "Appearance",
-            "kwargs": {
-                "renderMode": "ascii_shape",
-                "spriteNames": ["Apple",],
-                "spriteShapes": [shapes.LEGACY_APPLE],
-                "palettes": [shapes.GREEN_COIN_PALETTE],
-                "noRotates": [True],
-            }
-        },
-        {
-            "component": "Edible",
-            "kwargs": {
-                "liveState": "apple",
-                "waitState": "appleWait",
-                "rewardForEating": 1.0,
-            }
-        },
-        {
-            "component": "DensityRegrow",
-            "kwargs": {
-                "liveState": "apple",
-                "waitState": "appleWait",
-                "baseRate": 0.01,
-            }
-        },
-    ]
-}
-
-
-def get_config():
-  """Default configuration for the Harvest level."""
-  config = config_dict.ConfigDict()
-
-  # Basic configuration.
-  config.individual_observation_names = ["RGB"]
-  config.global_observation_names = ["WORLD.RGB"]
-
-  ascii_map = """
-**********************
-*      AAA       AAA *
-* AAA   A   AAA   A  *
-*AAAAA  _  AAAAA  _  *
-* AAA       AAA      *
-*      AAA       AAA *
-*     AAAAA  _  AAAAA*
-*      AAA       AAA *
-*  A         A       *
-* AAA   _   AAA   _  *
-**********************
-  """
-
-  # Lua script configuration.
-  config.lab2d_settings = {
-      "levelName":
-          "harvest_finished",
-      "levelDirectory":
-          "examples/tutorial/harvest/levels",
-      "maxEpisodeLengthFrames":
-          1000,
-      "numPlayers":
-          5,
-      "spriteSize":
-          8,
-      "simulation": {
-          "map": ascii_map,
-          "prefabs": {
-              "avatar": AVATAR,
-              "spawn_point": SPAWN_POINT,
-              "wall": WALL,
-              "apple": APPLE,
-          },
-          "charPrefabMap": {
-              "_": "spawn_point",
-              "*": "wall",
-              "A": "apple"
-          },
-          "playerPalettes": [],
-      },
-  }
-
-  return config
diff --git a/examples/tutorial/harvest/levels/harvest/init.lua b/examples/tutorial/harvest/levels/harvest/init.lua
deleted file mode 100644
index 7f943d6..0000000
--- a/examples/tutorial/harvest/levels/harvest/init.lua
+++ /dev/null
@@ -1,29 +0,0 @@
---[[ Copyright 2020 DeepMind Technologies Limited.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    https://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-]]
--- Entry point lua file for the Harvest level.
-
-local meltingpot = 'meltingpot.lua.modules.'
-local api_factory = require(meltingpot .. 'api_factory')
-local simulation = require(meltingpot .. 'base_simulation')
-
--- Required to be able to use the components in the level
-local component_library = require(meltingpot .. 'component_library')
-local avatar_library = require(meltingpot .. 'avatar_library')
-
-return api_factory.apiFactory{
-    Simulation = simulation.BaseSimulation,
-    settings = {
-    }
-}
diff --git a/examples/tutorial/harvest/levels/harvest_finished/components.lua b/examples/tutorial/harvest/levels/harvest_finished/components.lua
deleted file mode 100644
index adb4ed5..0000000
--- a/examples/tutorial/harvest/levels/harvest_finished/components.lua
+++ /dev/null
@@ -1,84 +0,0 @@
---[[ Copyright 2020 DeepMind Technologies Limited.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    https://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-]]
-local args = require 'common.args'
-local class = require 'common.class'
-local helpers = require 'common.helpers'
-local log = require 'common.log'
-local random = require 'system.random'
-local meltingpot = 'meltingpot.lua.modules.'
-local component = require(meltingpot .. 'component')
-local component_registry = require(meltingpot .. 'component_registry')
-
-
--- DensityRegrow makes the containing GameObject switch from `waitState` to
--- `liveState` at a rate based on the number of surrounding objects in
--- `liveState` and the configured `baseRate`.
-local DensityRegrow = class.Class(component.Component)
-
-function DensityRegrow:__init__(kwargs)
-  kwargs = args.parse(kwargs, {
-      {'name', args.default('DensityRegrow')},
-      -- `baseRate` indicates the base probability per frame of switching from
-      -- wait state to live state.
-      {'baseRate', args.ge(0.0), args.le(1.0)},
-      -- The name of the state representing the active or alive state.
-      {'liveState', args.stringType},
-      -- The name of the state representing the inactive or dormans state.
-      {'waitState', args.stringType},
-      -- The radius of the neighborhood
-      {'neighborhoodRadius', args.numberType, args.default(1)},
-      -- The layer to query for objects in `liveState`
-      {'queryLayer', args.stringType, args.default("lowerPhysical")},
-  })
-  DensityRegrow.Base.__init__(self, kwargs)
-
-  self._config.baseRate = kwargs.baseRate
-  self._config.liveState = kwargs.liveState
-  self._config.waitState = kwargs.waitState
-  self._config.neighborhoodRadius = kwargs.neighborhoodRadius
-  self._config.queryLayer = kwargs.queryLayer
-end
-
-function DensityRegrow:registerUpdaters(updaterRegistry)
-  updaterRegistry:registerUpdater{
-      state = self._config.waitState,
-      updateFn = function()
-          local transform = self.gameObject:getComponent("Transform")
-          -- Get neighbors
-          local objects = transform:queryDiamond(
-              self._config.queryLayer, self._config.neighborhoodRadius)
-          -- Count live neighbors
-          local liveNeighbors = 0
-          for _, object in pairs(objects) do
-            if object:getState() == self._config.liveState then
-              liveNeighbors = liveNeighbors + 1
-            end
-          end
-          local actualRate = liveNeighbors * self._config.baseRate
-          if random:uniformReal(0, 1) < actualRate then
-            self.gameObject:setState(self._config.liveState)
-          end
-        end,
-  }
-end
-
-
-local allComponents = {
-    DensityRegrow = DensityRegrow,
-}
-
-component_registry.registerAllComponents(allComponents)
-
-return allComponents
diff --git a/examples/tutorial/harvest/levels/harvest_finished/init.lua b/examples/tutorial/harvest/levels/harvest_finished/init.lua
deleted file mode 100644
index 085d49a..0000000
--- a/examples/tutorial/harvest/levels/harvest_finished/init.lua
+++ /dev/null
@@ -1,30 +0,0 @@
---[[ Copyright 2020 DeepMind Technologies Limited.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    https://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-]]
--- Entry point lua file for the Harvest level.
-
-local meltingpot = 'meltingpot.lua.modules.'
-local api_factory = require(meltingpot .. 'api_factory')
-local simulation = require(meltingpot .. 'base_simulation')
-
--- Required to be able to use the components in the level
-local component_library = require(meltingpot .. 'component_library')
-local avatar_library = require(meltingpot .. 'avatar_library')
-local components = require 'components'
-
-return api_factory.apiFactory{
-    Simulation = simulation.BaseSimulation,
-    settings = {
-    }
-}
diff --git a/examples/tutorial/harvest/play_harvest.py b/examples/tutorial/harvest/play_harvest.py
deleted file mode 100644
index 18f1b77..0000000
--- a/examples/tutorial/harvest/play_harvest.py
+++ /dev/null
@@ -1,67 +0,0 @@
-# Copyright 2020 DeepMind Technologies Limited.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     https://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-"""A simple human player for playing the `Harvest` level interactively.
-
-Use `WASD` keys to move the character around. `Q` and `E` to turn.
-"""
-from absl import app
-from absl import flags
-from meltingpot.human_players import level_playing_utils
-
-from .configs.environment import harvest as game
-
-FLAGS = flags.FLAGS
-
-flags.DEFINE_integer('screen_width', 800,
-                     'Width, in pixels, of the game screen')
-flags.DEFINE_integer('screen_height', 600,
-                     'Height, in pixels, of the game screen')
-flags.DEFINE_integer('frames_per_second', 8, 'Frames per second of the game')
-flags.DEFINE_string('observation', 'RGB', 'Name of the observation to render')
-flags.DEFINE_bool('verbose', False, 'Whether we want verbose output')
-flags.DEFINE_bool('display_text', False,
-                  'Whether we to display a debug text message')
-flags.DEFINE_string('text_message', 'This page intentionally left blank',
-                    'Text to display if `display_text` is `True`')
-
-
-_ACTION_MAP = {
-    'move': level_playing_utils.get_direction_pressed,
-    'turn': level_playing_utils.get_turn_pressed,
-}
-
-
-def verbose_fn(unused_timestep, unused_player_index: int) -> None:
-  pass
-
-
-def text_display_fn(unused_timestep, unused_player_index: int) -> str:
-  return FLAGS.text_message
-
-
-def main(argv):
-  del argv  # Unused.
-  level_playing_utils.run_episode(
-      FLAGS.observation,
-      {},  # Settings overrides
-      _ACTION_MAP,
-      game.get_config(),
-      level_playing_utils.RenderType.PYGAME,
-      FLAGS.screen_width, FLAGS.screen_height, FLAGS.frames_per_second,
-      verbose_fn if FLAGS.verbose else None,
-      text_display_fn if FLAGS.display_text else None)
-
-
-if __name__ == '__main__':
-  app.run(main)
